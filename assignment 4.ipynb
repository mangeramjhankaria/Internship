{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "616f327f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "from selenium import webdriver\n",
    "import pandas as pd\n",
    "from selenium.webdriver.common.by import By\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b6f1e7e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "64308bd4",
   "metadata": {},
   "source": [
    "# Q1 : Scrape the details of most viewed videos on YouTube from Wikipedia:\n",
    " Url = https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos/\n",
    " You need to find following details:\n",
    " A) Rank\n",
    " B) Name\n",
    " C) Artist\n",
    " D) Upload date\n",
    " E) Views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "97573b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first, connect to the webdriver\n",
    "driver=webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b175ff72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the webpage of mentioned url\n",
    "driver.get(\"https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2f54d3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Rank = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5a8f88f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping Rank of the videos\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,'//table[@class=\"wikitable sortable jquery-tablesorter\"][1]/tbody/tr/td[1]'):\n",
    "        Rank.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Rank.append(\"-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "de17758d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Name = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b46ef353",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping Name of the videos\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,'//table[@class=\"wikitable sortable jquery-tablesorter\"][1]/tbody/tr/td[2]'):\n",
    "        Name.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Name.append(\"-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "09a5301a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Artist = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8b48f228",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping Artist of the videos\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,'//table[@class=\"wikitable sortable jquery-tablesorter\"][1]/tbody/tr/td[3]'):\n",
    "        Artist.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Artist.append(\"-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "812b9451",
   "metadata": {},
   "outputs": [],
   "source": [
    "Date = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "38a1f1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping Upload_Date of the videos\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,'//table[@class=\"wikitable sortable jquery-tablesorter\"][1]/tbody/tr/td[5]'):\n",
    "        Date.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Date.append(\"-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "00857a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "Views = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "22314f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping Views of the videos\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,'//table[@class=\"wikitable sortable jquery-tablesorter\"][1]/tbody/tr/td[4]'):\n",
    "        Views.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Views.append(\"-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7719162a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Name</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Upload date</th>\n",
       "      <th>Views</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.</td>\n",
       "      <td>\"Baby Shark Dance\"[6]</td>\n",
       "      <td>Pinkfong Baby Shark - Kids' Songs &amp; Stories</td>\n",
       "      <td>June 17, 2016</td>\n",
       "      <td>13.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.</td>\n",
       "      <td>\"Despacito\"[9]</td>\n",
       "      <td>Luis Fonsi</td>\n",
       "      <td>January 12, 2017</td>\n",
       "      <td>8.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.</td>\n",
       "      <td>\"Johny Johny Yes Papa\"[17]</td>\n",
       "      <td>LooLoo Kids - Nursery Rhymes and Children's Songs</td>\n",
       "      <td>October 8, 2016</td>\n",
       "      <td>6.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.</td>\n",
       "      <td>\"Bath Song\"[18]</td>\n",
       "      <td>Cocomelon - Nursery Rhymes</td>\n",
       "      <td>May 2, 2018</td>\n",
       "      <td>6.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.</td>\n",
       "      <td>\"Shape of You\"[19]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>January 30, 2017</td>\n",
       "      <td>6.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.</td>\n",
       "      <td>\"See You Again\"[22]</td>\n",
       "      <td>Wiz Khalifa</td>\n",
       "      <td>April 6, 2015</td>\n",
       "      <td>6.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.</td>\n",
       "      <td>\"Wheels on the Bus\"[27]</td>\n",
       "      <td>Cocomelon - Nursery Rhymes</td>\n",
       "      <td>May 24, 2018</td>\n",
       "      <td>5.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.</td>\n",
       "      <td>\"Phonics Song with Two Words\"[28]</td>\n",
       "      <td>ChuChu TV Nursery Rhymes &amp; Kids Songs</td>\n",
       "      <td>March 6, 2014</td>\n",
       "      <td>5.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.</td>\n",
       "      <td>\"Uptown Funk\"[29]</td>\n",
       "      <td>Mark Ronson</td>\n",
       "      <td>November 19, 2014</td>\n",
       "      <td>5.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.</td>\n",
       "      <td>\"Learning Colors – Colorful Eggs on a Farm\"[30]</td>\n",
       "      <td>Miroshka TV</td>\n",
       "      <td>February 27, 2018</td>\n",
       "      <td>5.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11.</td>\n",
       "      <td>\"Gangnam Style\"[31]</td>\n",
       "      <td>officialpsy</td>\n",
       "      <td>July 15, 2012</td>\n",
       "      <td>4.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12.</td>\n",
       "      <td>\"Masha and the Bear – Recipe for Disaster\"[36]</td>\n",
       "      <td>Get Movies</td>\n",
       "      <td>January 31, 2012</td>\n",
       "      <td>4.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13.</td>\n",
       "      <td>\"Dame Tu Cosita\"[37]</td>\n",
       "      <td>Ultra Records</td>\n",
       "      <td>April 5, 2018</td>\n",
       "      <td>4.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14.</td>\n",
       "      <td>\"Axel F\"[38]</td>\n",
       "      <td>Crazy Frog</td>\n",
       "      <td>June 16, 2009</td>\n",
       "      <td>4.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15.</td>\n",
       "      <td>\"Sugar\"[39]</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>January 14, 2015</td>\n",
       "      <td>3.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16.</td>\n",
       "      <td>\"Counting Stars\"[40]</td>\n",
       "      <td>OneRepublic</td>\n",
       "      <td>May 31, 2013</td>\n",
       "      <td>3.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17.</td>\n",
       "      <td>\"Roar\"[41]</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>September 5, 2013</td>\n",
       "      <td>3.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18.</td>\n",
       "      <td>\"Baa Baa Black Sheep\"[42]</td>\n",
       "      <td>Cocomelon - Nursery Rhymes</td>\n",
       "      <td>June 25, 2018</td>\n",
       "      <td>3.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19.</td>\n",
       "      <td>\"Waka Waka (This Time for Africa)\"[43]</td>\n",
       "      <td>Shakira</td>\n",
       "      <td>June 4, 2010</td>\n",
       "      <td>3.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20.</td>\n",
       "      <td>\"Lakdi Ki Kathi\"[44]</td>\n",
       "      <td>Jingle Toons</td>\n",
       "      <td>June 14, 2018</td>\n",
       "      <td>3.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21.</td>\n",
       "      <td>\"Sorry\"[45]</td>\n",
       "      <td>Justin Bieber</td>\n",
       "      <td>October 22, 2015</td>\n",
       "      <td>3.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22.</td>\n",
       "      <td>\"Thinking Out Loud\"[46]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>October 7, 2014</td>\n",
       "      <td>3.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23.</td>\n",
       "      <td>\"Humpty the train on a fruits ride\"[47]</td>\n",
       "      <td>Kiddiestv Hindi - Nursery Rhymes &amp; Kids Songs</td>\n",
       "      <td>January 26, 2018</td>\n",
       "      <td>3.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24.</td>\n",
       "      <td>\"Dark Horse\"[48]</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>February 20, 2014</td>\n",
       "      <td>3.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25.</td>\n",
       "      <td>\"Perfect\"[49]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>November 9, 2017</td>\n",
       "      <td>3.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26.</td>\n",
       "      <td>\"Let Her Go\"[50]</td>\n",
       "      <td>Passenger</td>\n",
       "      <td>July 25, 2012</td>\n",
       "      <td>3.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27.</td>\n",
       "      <td>\"Faded\"[51]</td>\n",
       "      <td>Alan Walker</td>\n",
       "      <td>December 3, 2015</td>\n",
       "      <td>3.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28.</td>\n",
       "      <td>\"Shree Hanuman Chalisa\"[52]</td>\n",
       "      <td>T-Series Bhakti Sagar</td>\n",
       "      <td>May 10, 2011</td>\n",
       "      <td>3.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29.</td>\n",
       "      <td>\"Girls Like You\"[53]</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>May 31, 2018</td>\n",
       "      <td>3.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30.</td>\n",
       "      <td>\"Lean On\"[54]</td>\n",
       "      <td>Major Lazer Official</td>\n",
       "      <td>March 22, 2015</td>\n",
       "      <td>3.50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                                             Name  \\\n",
       "0    1.                            \"Baby Shark Dance\"[6]   \n",
       "1    2.                                   \"Despacito\"[9]   \n",
       "2    3.                       \"Johny Johny Yes Papa\"[17]   \n",
       "3    4.                                  \"Bath Song\"[18]   \n",
       "4    5.                               \"Shape of You\"[19]   \n",
       "5    6.                              \"See You Again\"[22]   \n",
       "6    7.                          \"Wheels on the Bus\"[27]   \n",
       "7    8.                \"Phonics Song with Two Words\"[28]   \n",
       "8    9.                                \"Uptown Funk\"[29]   \n",
       "9   10.  \"Learning Colors – Colorful Eggs on a Farm\"[30]   \n",
       "10  11.                              \"Gangnam Style\"[31]   \n",
       "11  12.   \"Masha and the Bear – Recipe for Disaster\"[36]   \n",
       "12  13.                             \"Dame Tu Cosita\"[37]   \n",
       "13  14.                                     \"Axel F\"[38]   \n",
       "14  15.                                      \"Sugar\"[39]   \n",
       "15  16.                             \"Counting Stars\"[40]   \n",
       "16  17.                                       \"Roar\"[41]   \n",
       "17  18.                        \"Baa Baa Black Sheep\"[42]   \n",
       "18  19.           \"Waka Waka (This Time for Africa)\"[43]   \n",
       "19  20.                             \"Lakdi Ki Kathi\"[44]   \n",
       "20  21.                                      \"Sorry\"[45]   \n",
       "21  22.                          \"Thinking Out Loud\"[46]   \n",
       "22  23.          \"Humpty the train on a fruits ride\"[47]   \n",
       "23  24.                                 \"Dark Horse\"[48]   \n",
       "24  25.                                    \"Perfect\"[49]   \n",
       "25  26.                                 \"Let Her Go\"[50]   \n",
       "26  27.                                      \"Faded\"[51]   \n",
       "27  28.                      \"Shree Hanuman Chalisa\"[52]   \n",
       "28  29.                             \"Girls Like You\"[53]   \n",
       "29  30.                                    \"Lean On\"[54]   \n",
       "\n",
       "                                               Artist        Upload date  \\\n",
       "0         Pinkfong Baby Shark - Kids' Songs & Stories      June 17, 2016   \n",
       "1                                          Luis Fonsi   January 12, 2017   \n",
       "2   LooLoo Kids - Nursery Rhymes and Children's Songs    October 8, 2016   \n",
       "3                          Cocomelon - Nursery Rhymes        May 2, 2018   \n",
       "4                                          Ed Sheeran   January 30, 2017   \n",
       "5                                         Wiz Khalifa      April 6, 2015   \n",
       "6                          Cocomelon - Nursery Rhymes       May 24, 2018   \n",
       "7               ChuChu TV Nursery Rhymes & Kids Songs      March 6, 2014   \n",
       "8                                         Mark Ronson  November 19, 2014   \n",
       "9                                         Miroshka TV  February 27, 2018   \n",
       "10                                        officialpsy      July 15, 2012   \n",
       "11                                         Get Movies   January 31, 2012   \n",
       "12                                      Ultra Records      April 5, 2018   \n",
       "13                                         Crazy Frog      June 16, 2009   \n",
       "14                                           Maroon 5   January 14, 2015   \n",
       "15                                        OneRepublic       May 31, 2013   \n",
       "16                                         Katy Perry  September 5, 2013   \n",
       "17                         Cocomelon - Nursery Rhymes      June 25, 2018   \n",
       "18                                            Shakira       June 4, 2010   \n",
       "19                                       Jingle Toons      June 14, 2018   \n",
       "20                                      Justin Bieber   October 22, 2015   \n",
       "21                                         Ed Sheeran    October 7, 2014   \n",
       "22      Kiddiestv Hindi - Nursery Rhymes & Kids Songs   January 26, 2018   \n",
       "23                                         Katy Perry  February 20, 2014   \n",
       "24                                         Ed Sheeran   November 9, 2017   \n",
       "25                                          Passenger      July 25, 2012   \n",
       "26                                        Alan Walker   December 3, 2015   \n",
       "27                              T-Series Bhakti Sagar       May 10, 2011   \n",
       "28                                           Maroon 5       May 31, 2018   \n",
       "29                               Major Lazer Official     March 22, 2015   \n",
       "\n",
       "    Views  \n",
       "0   13.65  \n",
       "1    8.32  \n",
       "2    6.84  \n",
       "3    6.50  \n",
       "4    6.14  \n",
       "5    6.09  \n",
       "6    5.71  \n",
       "7    5.57  \n",
       "8    5.09  \n",
       "9    5.01  \n",
       "10   4.96  \n",
       "11   4.57  \n",
       "12   4.48  \n",
       "13   4.16  \n",
       "14   3.97  \n",
       "15   3.92  \n",
       "16   3.91  \n",
       "17   3.84  \n",
       "18   3.78  \n",
       "19   3.76  \n",
       "20   3.74  \n",
       "21   3.69  \n",
       "22   3.63  \n",
       "23   3.63  \n",
       "24   3.60  \n",
       "25   3.56  \n",
       "26   3.55  \n",
       "27   3.54  \n",
       "28   3.52  \n",
       "29   3.50  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating DataFrame for scraped data\n",
    "df = pd.DataFrame({'Rank':Rank,'Name':Name,'Artist':Artist,'Upload date':Date,'Views':Views})\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f59b827",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0e30e073",
   "metadata": {},
   "source": [
    "# 2. Scrape the details team India’s international fixtures from bcci.tv.\n",
    "Url = https://www.bcci.tv/.\n",
    "You need to find following details:\n",
    "           \n",
    "            A) Series\n",
    "            B) Place\n",
    "            C) Date\n",
    "            D) Time\n",
    "Note: - From bcci.tv home page you have reach to the international fixture page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "aa4ddd42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first, connect to the webdriver\n",
    "driver=webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8a159846",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the webpage of mentioned url\n",
    "driver.get(\"https://www.bcci.tv/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2701fe81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clicking on fixtures button\n",
    "button=driver.find_element(By.XPATH,'/html/body/header/div[3]/div[1]/ul/div[1]/a[2]')\n",
    "driver.get(button.get_attribute(\"href\"))\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "98050984",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clicking on more Matches button\n",
    "driver.find_element(By.XPATH,'/html/body/section/div/div/div/div/div/div[2]/div[2]/div[2]/div/button').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a7d2f803",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating empty lists for scraping the data\n",
    "Series = []\n",
    "Place = []\n",
    "Date = []\n",
    "Time = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "052e4ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping series\n",
    "for i in driver.find_elements(By.XPATH,'//h5[@class=\"match-tournament-name ng-binding\"]'):\n",
    "    Series.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "dd4b8517",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping place\n",
    "for i in driver.find_elements(By.XPATH,'//div[@class=\"match-place ng-scope\"]'):\n",
    "    Place.append(i.text.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "6075eb30",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping Date\n",
    "for i in driver.find_elements(By.XPATH,'//div[@class=\"match-dates ng-binding\"]'):\n",
    "    Date.append(i.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d79a700d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping Time\n",
    "for i in driver.find_elements(By.XPATH,'//div[@class=\"match-time no-margin ng-binding\"]'):\n",
    "    Time.append(i.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "01cc30db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Series</th>\n",
       "      <th>Place</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AUSTRALIA TOUR OF INDIA 2023-24</td>\n",
       "      <td>[Barsapara, Cricket, Stadium,, Guwahati]</td>\n",
       "      <td>28 NOVEMBER, 2023</td>\n",
       "      <td>7:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENGLAND A WOMENS TOUR OF INDIA T20 SERIES</td>\n",
       "      <td>[Wankhede, Stadium,, Mumbai]</td>\n",
       "      <td>29 NOVEMBER, 2023</td>\n",
       "      <td>1:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ENGLAND A WOMENS TOUR OF INDIA T20 SERIES</td>\n",
       "      <td>[Wankhede, Stadium,, Mumbai]</td>\n",
       "      <td>1 DECEMBER, 2023</td>\n",
       "      <td>1:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AUSTRALIA TOUR OF INDIA 2023-24</td>\n",
       "      <td>[Shaheed, Veer, Narayan, Singh, International,...</td>\n",
       "      <td>1 DECEMBER, 2023</td>\n",
       "      <td>7:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENGLAND A WOMENS TOUR OF INDIA T20 SERIES</td>\n",
       "      <td>[Wankhede, Stadium,, Mumbai]</td>\n",
       "      <td>3 DECEMBER, 2023</td>\n",
       "      <td>1:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AUSTRALIA TOUR OF INDIA 2023-24</td>\n",
       "      <td>[M, Chinnaswamy, Stadium,, Bengaluru]</td>\n",
       "      <td>3 DECEMBER, 2023</td>\n",
       "      <td>7:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ENGLAND WOMEN TOUR OF INDIA 2023-24</td>\n",
       "      <td>[Wankhede, Stadium,, Mumbai]</td>\n",
       "      <td>6 DECEMBER, 2023</td>\n",
       "      <td>7:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ENGLAND WOMEN TOUR OF INDIA 2023-24</td>\n",
       "      <td>[Wankhede, Stadium,, Mumbai]</td>\n",
       "      <td>9 DECEMBER, 2023</td>\n",
       "      <td>7:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ENGLAND WOMEN TOUR OF INDIA 2023-24</td>\n",
       "      <td>[Wankhede, Stadium,, Mumbai]</td>\n",
       "      <td>10 DECEMBER, 2023</td>\n",
       "      <td>7:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>INDIA TOUR OF SOUTH AFRICA 2023-24</td>\n",
       "      <td>[Kingsmead,, Durban]</td>\n",
       "      <td>10 DECEMBER, 2023</td>\n",
       "      <td>9:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>INDIA TOUR OF SOUTH AFRICA 2023-24</td>\n",
       "      <td>[St, George's, Park,, Gqeberha]</td>\n",
       "      <td>12 DECEMBER, 2023</td>\n",
       "      <td>9:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ENGLAND WOMEN TOUR OF INDIA 2023-24</td>\n",
       "      <td>[DY, Patil, Stadium,, NAVI, MUMBAI]</td>\n",
       "      <td>14 DECEMBER, 2023</td>\n",
       "      <td>9:30 AM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>INDIA TOUR OF SOUTH AFRICA 2023-24</td>\n",
       "      <td>[The, Wanderers, Stadium,, Johannesburg]</td>\n",
       "      <td>14 DECEMBER, 2023</td>\n",
       "      <td>9:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>INDIA TOUR OF SOUTH AFRICA 2023-24</td>\n",
       "      <td>[Johannesburg]</td>\n",
       "      <td>17 DECEMBER, 2023</td>\n",
       "      <td>2:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>INDIA TOUR OF SOUTH AFRICA 2023-24</td>\n",
       "      <td>[St, George's, Park,, Gqeberha]</td>\n",
       "      <td>19 DECEMBER, 2023</td>\n",
       "      <td>2:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>AUSTRALIA WOMEN TOUR OF INDIA 2023-24</td>\n",
       "      <td>[Wankhede, Stadium,, Mumbai]</td>\n",
       "      <td>21 DECEMBER, 2023</td>\n",
       "      <td>9:30 AM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>INDIA TOUR OF SOUTH AFRICA 2023-24</td>\n",
       "      <td>[Boland, Park,, Paarl]</td>\n",
       "      <td>21 DECEMBER, 2023</td>\n",
       "      <td>2:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>INDIA TOUR OF SOUTH AFRICA 2023-24</td>\n",
       "      <td>[SuperSport, Park,, Centurion]</td>\n",
       "      <td>26 DECEMBER, 2023</td>\n",
       "      <td>1:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>AUSTRALIA WOMEN TOUR OF INDIA 2023-24</td>\n",
       "      <td>[Wankhede, Stadium,, Mumbai]</td>\n",
       "      <td>28 DECEMBER, 2023</td>\n",
       "      <td>2:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>AUSTRALIA WOMEN TOUR OF INDIA 2023-24</td>\n",
       "      <td>[Wankhede, Stadium,, Mumbai]</td>\n",
       "      <td>30 DECEMBER, 2023</td>\n",
       "      <td>2:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>AUSTRALIA WOMEN TOUR OF INDIA 2023-24</td>\n",
       "      <td>[Wankhede, Stadium,, Mumbai]</td>\n",
       "      <td>2 JANUARY, 2024</td>\n",
       "      <td>2:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>INDIA TOUR OF SOUTH AFRICA 2023-24</td>\n",
       "      <td>[Newlands,, Cape, Town]</td>\n",
       "      <td>3 JANUARY, 2024</td>\n",
       "      <td>1:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>AUSTRALIA WOMEN TOUR OF INDIA 2023-24</td>\n",
       "      <td>[DY, Patil, Stadium,, NAVI, MUMBAI]</td>\n",
       "      <td>5 JANUARY, 2024</td>\n",
       "      <td>7:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>AUSTRALIA WOMEN TOUR OF INDIA 2023-24</td>\n",
       "      <td>[DY, Patil, Stadium,, NAVI, MUMBAI]</td>\n",
       "      <td>7 JANUARY, 2024</td>\n",
       "      <td>7:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>AUSTRALIA WOMEN TOUR OF INDIA 2023-24</td>\n",
       "      <td>[DY, Patil, Stadium,, NAVI, MUMBAI]</td>\n",
       "      <td>9 JANUARY, 2024</td>\n",
       "      <td>7:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>AFGHANISTAN TOUR OF INDIA 2023-24</td>\n",
       "      <td>[Punjab, Cricket, Association, IS, Bindra, Sta...</td>\n",
       "      <td>11 JANUARY, 2024</td>\n",
       "      <td>7:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>AFGHANISTAN TOUR OF INDIA 2023-24</td>\n",
       "      <td>[Holkar, Cricket, Stadium,, Indore]</td>\n",
       "      <td>14 JANUARY, 2024</td>\n",
       "      <td>7:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>AFGHANISTAN TOUR OF INDIA 2023-24</td>\n",
       "      <td>[M, Chinnaswamy, Stadium,, Bengaluru]</td>\n",
       "      <td>17 JANUARY, 2024</td>\n",
       "      <td>7:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>ENGLAND TOUR OF INDIA 2023-24</td>\n",
       "      <td>[Rajiv, Gandhi, International, Stadium,, Hyder...</td>\n",
       "      <td>25 JANUARY, 2024</td>\n",
       "      <td>9:30 AM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>ENGLAND TOUR OF INDIA 2023-24</td>\n",
       "      <td>[Dr, YS, Rajasekhara, Reddy, ACA-VDCA, Cricket...</td>\n",
       "      <td>2 FEBRUARY, 2024</td>\n",
       "      <td>9:30 AM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>ENGLAND TOUR OF INDIA 2023-24</td>\n",
       "      <td>[Saurashtra, Cricket, Association, Stadium,, R...</td>\n",
       "      <td>15 FEBRUARY, 2024</td>\n",
       "      <td>9:30 AM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>ENGLAND TOUR OF INDIA 2023-24</td>\n",
       "      <td>[JSCA, International, Stadium, Complex,, Ranchi]</td>\n",
       "      <td>23 FEBRUARY, 2024</td>\n",
       "      <td>9:30 AM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>ENGLAND TOUR OF INDIA 2023-24</td>\n",
       "      <td>[Himachal, Pradesh, Cricket, Association, Stad...</td>\n",
       "      <td>7 MARCH, 2024</td>\n",
       "      <td>9:30 AM IST</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Series  \\\n",
       "0             AUSTRALIA TOUR OF INDIA 2023-24   \n",
       "1   ENGLAND A WOMENS TOUR OF INDIA T20 SERIES   \n",
       "2   ENGLAND A WOMENS TOUR OF INDIA T20 SERIES   \n",
       "3             AUSTRALIA TOUR OF INDIA 2023-24   \n",
       "4   ENGLAND A WOMENS TOUR OF INDIA T20 SERIES   \n",
       "5             AUSTRALIA TOUR OF INDIA 2023-24   \n",
       "6         ENGLAND WOMEN TOUR OF INDIA 2023-24   \n",
       "7         ENGLAND WOMEN TOUR OF INDIA 2023-24   \n",
       "8         ENGLAND WOMEN TOUR OF INDIA 2023-24   \n",
       "9          INDIA TOUR OF SOUTH AFRICA 2023-24   \n",
       "10         INDIA TOUR OF SOUTH AFRICA 2023-24   \n",
       "11        ENGLAND WOMEN TOUR OF INDIA 2023-24   \n",
       "12         INDIA TOUR OF SOUTH AFRICA 2023-24   \n",
       "13         INDIA TOUR OF SOUTH AFRICA 2023-24   \n",
       "14         INDIA TOUR OF SOUTH AFRICA 2023-24   \n",
       "15      AUSTRALIA WOMEN TOUR OF INDIA 2023-24   \n",
       "16         INDIA TOUR OF SOUTH AFRICA 2023-24   \n",
       "17         INDIA TOUR OF SOUTH AFRICA 2023-24   \n",
       "18      AUSTRALIA WOMEN TOUR OF INDIA 2023-24   \n",
       "19      AUSTRALIA WOMEN TOUR OF INDIA 2023-24   \n",
       "20      AUSTRALIA WOMEN TOUR OF INDIA 2023-24   \n",
       "21         INDIA TOUR OF SOUTH AFRICA 2023-24   \n",
       "22      AUSTRALIA WOMEN TOUR OF INDIA 2023-24   \n",
       "23      AUSTRALIA WOMEN TOUR OF INDIA 2023-24   \n",
       "24      AUSTRALIA WOMEN TOUR OF INDIA 2023-24   \n",
       "25          AFGHANISTAN TOUR OF INDIA 2023-24   \n",
       "26          AFGHANISTAN TOUR OF INDIA 2023-24   \n",
       "27          AFGHANISTAN TOUR OF INDIA 2023-24   \n",
       "28              ENGLAND TOUR OF INDIA 2023-24   \n",
       "29              ENGLAND TOUR OF INDIA 2023-24   \n",
       "30              ENGLAND TOUR OF INDIA 2023-24   \n",
       "31              ENGLAND TOUR OF INDIA 2023-24   \n",
       "32              ENGLAND TOUR OF INDIA 2023-24   \n",
       "\n",
       "                                                Place               Date  \\\n",
       "0            [Barsapara, Cricket, Stadium,, Guwahati]  28 NOVEMBER, 2023   \n",
       "1                        [Wankhede, Stadium,, Mumbai]  29 NOVEMBER, 2023   \n",
       "2                        [Wankhede, Stadium,, Mumbai]   1 DECEMBER, 2023   \n",
       "3   [Shaheed, Veer, Narayan, Singh, International,...   1 DECEMBER, 2023   \n",
       "4                        [Wankhede, Stadium,, Mumbai]   3 DECEMBER, 2023   \n",
       "5               [M, Chinnaswamy, Stadium,, Bengaluru]   3 DECEMBER, 2023   \n",
       "6                        [Wankhede, Stadium,, Mumbai]   6 DECEMBER, 2023   \n",
       "7                        [Wankhede, Stadium,, Mumbai]   9 DECEMBER, 2023   \n",
       "8                        [Wankhede, Stadium,, Mumbai]  10 DECEMBER, 2023   \n",
       "9                                [Kingsmead,, Durban]  10 DECEMBER, 2023   \n",
       "10                    [St, George's, Park,, Gqeberha]  12 DECEMBER, 2023   \n",
       "11                [DY, Patil, Stadium,, NAVI, MUMBAI]  14 DECEMBER, 2023   \n",
       "12           [The, Wanderers, Stadium,, Johannesburg]  14 DECEMBER, 2023   \n",
       "13                                     [Johannesburg]  17 DECEMBER, 2023   \n",
       "14                    [St, George's, Park,, Gqeberha]  19 DECEMBER, 2023   \n",
       "15                       [Wankhede, Stadium,, Mumbai]  21 DECEMBER, 2023   \n",
       "16                             [Boland, Park,, Paarl]  21 DECEMBER, 2023   \n",
       "17                     [SuperSport, Park,, Centurion]  26 DECEMBER, 2023   \n",
       "18                       [Wankhede, Stadium,, Mumbai]  28 DECEMBER, 2023   \n",
       "19                       [Wankhede, Stadium,, Mumbai]  30 DECEMBER, 2023   \n",
       "20                       [Wankhede, Stadium,, Mumbai]    2 JANUARY, 2024   \n",
       "21                            [Newlands,, Cape, Town]    3 JANUARY, 2024   \n",
       "22                [DY, Patil, Stadium,, NAVI, MUMBAI]    5 JANUARY, 2024   \n",
       "23                [DY, Patil, Stadium,, NAVI, MUMBAI]    7 JANUARY, 2024   \n",
       "24                [DY, Patil, Stadium,, NAVI, MUMBAI]    9 JANUARY, 2024   \n",
       "25  [Punjab, Cricket, Association, IS, Bindra, Sta...   11 JANUARY, 2024   \n",
       "26                [Holkar, Cricket, Stadium,, Indore]   14 JANUARY, 2024   \n",
       "27              [M, Chinnaswamy, Stadium,, Bengaluru]   17 JANUARY, 2024   \n",
       "28  [Rajiv, Gandhi, International, Stadium,, Hyder...   25 JANUARY, 2024   \n",
       "29  [Dr, YS, Rajasekhara, Reddy, ACA-VDCA, Cricket...   2 FEBRUARY, 2024   \n",
       "30  [Saurashtra, Cricket, Association, Stadium,, R...  15 FEBRUARY, 2024   \n",
       "31   [JSCA, International, Stadium, Complex,, Ranchi]  23 FEBRUARY, 2024   \n",
       "32  [Himachal, Pradesh, Cricket, Association, Stad...      7 MARCH, 2024   \n",
       "\n",
       "           Time  \n",
       "0   7:00 PM IST  \n",
       "1   1:30 PM IST  \n",
       "2   1:30 PM IST  \n",
       "3   7:00 PM IST  \n",
       "4   1:30 PM IST  \n",
       "5   7:00 PM IST  \n",
       "6   7:00 PM IST  \n",
       "7   7:00 PM IST  \n",
       "8   7:00 PM IST  \n",
       "9   9:30 PM IST  \n",
       "10  9:30 PM IST  \n",
       "11  9:30 AM IST  \n",
       "12  9:30 PM IST  \n",
       "13  2:00 PM IST  \n",
       "14  2:00 PM IST  \n",
       "15  9:30 AM IST  \n",
       "16  2:00 PM IST  \n",
       "17  1:30 PM IST  \n",
       "18  2:00 PM IST  \n",
       "19  2:00 PM IST  \n",
       "20  2:00 PM IST  \n",
       "21  1:30 PM IST  \n",
       "22  7:00 PM IST  \n",
       "23  7:00 PM IST  \n",
       "24  7:00 PM IST  \n",
       "25  7:00 PM IST  \n",
       "26  7:00 PM IST  \n",
       "27  7:00 PM IST  \n",
       "28  9:30 AM IST  \n",
       "29  9:30 AM IST  \n",
       "30  9:30 AM IST  \n",
       "31  9:30 AM IST  \n",
       "32  9:30 AM IST  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating DataFrame for scraped data\n",
    "df = pd.DataFrame({'Series':Series,'Place':Place,'Date':Date,'Time':Time,})\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d54297d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cc31d1be",
   "metadata": {},
   "source": [
    "# 3. Scrape the details of State-wise GDP of India from statisticstime.com.\n",
    "Url = http://statisticstimes.com/\n",
    "You have to find following details: \n",
    "\n",
    "A) Rank\n",
    "B) State\n",
    "C) GSDP(18-19)- at current prices\n",
    "D) GSDP(19-20)- at current prices\n",
    "E) Share(18-19)\n",
    "F) GDP($ billion) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "51a1793d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first, connect to the webdriver\n",
    "driver=webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6fd68ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the webpage of mentioned url\n",
    "driver.get(\"https://statisticstimes.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d24385da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clicking on Economy button\n",
    "driver.find_element(By.XPATH,'//div[@class=\"navbar\"]/div[2]/button').click()\n",
    "\n",
    "# clicking on India\n",
    "driver.find_element(By.XPATH,'//div[@class=\"dropdown-content\"]/a[3]').click()\n",
    "time.sleep(3)\n",
    "\n",
    "# clicking on GDP of Indian Economy\n",
    "GDP = driver.find_element(By.XPATH,'/html/body/div[2]/div[2]/div[2]/ul/li[1]/a').click()\n",
    "time.sleep(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4be96a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating empty list\n",
    "Rank = []\n",
    "State = []\n",
    "GSDP1 = []\n",
    "GSDP2 = []\n",
    "Share = []\n",
    "GDP_billion = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4249012d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping Rank\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,'//table[@class=\"display dataTable\"]/tbody/tr/td[1]'):\n",
    "        Rank.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Rank.append(\"_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f68f436c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping State\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,'//table[@class=\"display dataTable\"]/tbody/tr/td[2]'):\n",
    "        State.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    State.append(\"_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3d5aff23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping GSDP at current price (18-19)\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,'//table[@class=\"display dataTable\"]/tbody/tr/td[4]'):\n",
    "        GSDP1.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    GSDP1.append(\"_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6825a8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping GSDP at current price (19-20)\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,'//table[@class=\"display dataTable\"]/tbody/tr/td[3]'):\n",
    "        GSDP2.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    GSDP2.append(\"_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dc23fa1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping Share (18-19)\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,'//table[@class=\"display dataTable\"]/tbody/tr/td[5]'):\n",
    "        Share.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Share.append(\"_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6409bcc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping GDP $ billion\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,'//table[@class=\"display dataTable\"]/tbody/tr/td[6]'):\n",
    "        GDP_billion.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    GDP_billion.append(\"_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "80eb7d57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>State</th>\n",
       "      <th>GSDP(18-19)-at current prices</th>\n",
       "      <th>GSDP(19-20)-at current prices</th>\n",
       "      <th>Share(18-19)</th>\n",
       "      <th>GDP($ Billion)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>2,632,792</td>\n",
       "      <td>-</td>\n",
       "      <td>13.94%</td>\n",
       "      <td>399.921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Tamil Nadu</td>\n",
       "      <td>1,630,208</td>\n",
       "      <td>1,845,853</td>\n",
       "      <td>8.63%</td>\n",
       "      <td>247.629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>1,584,764</td>\n",
       "      <td>1,687,818</td>\n",
       "      <td>8.39%</td>\n",
       "      <td>240.726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Gujarat</td>\n",
       "      <td>1,502,899</td>\n",
       "      <td>-</td>\n",
       "      <td>7.96%</td>\n",
       "      <td>228.290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Karnataka</td>\n",
       "      <td>1,493,127</td>\n",
       "      <td>1,631,977</td>\n",
       "      <td>7.91%</td>\n",
       "      <td>226.806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>29</td>\n",
       "      <td>Sikkim</td>\n",
       "      <td>25,141</td>\n",
       "      <td>28,391</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>17,060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>30</td>\n",
       "      <td>Nagaland</td>\n",
       "      <td>24,534</td>\n",
       "      <td>-</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>31</td>\n",
       "      <td>Arunachal Pradesh</td>\n",
       "      <td>22,488</td>\n",
       "      <td>-</td>\n",
       "      <td>0.13%</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>32</td>\n",
       "      <td>Mizoram</td>\n",
       "      <td>20,947</td>\n",
       "      <td>24,424</td>\n",
       "      <td>0.13%</td>\n",
       "      <td>17,797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>33</td>\n",
       "      <td>Andaman &amp; Nicobar Islands</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>66 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                      State GSDP(18-19)-at current prices  \\\n",
       "0     1                Maharashtra                     2,632,792   \n",
       "1     2                 Tamil Nadu                     1,630,208   \n",
       "2     3              Uttar Pradesh                     1,584,764   \n",
       "3     4                    Gujarat                     1,502,899   \n",
       "4     5                  Karnataka                     1,493,127   \n",
       "..  ...                        ...                           ...   \n",
       "61   29                     Sikkim                        25,141   \n",
       "62   30                   Nagaland                        24,534   \n",
       "63   31          Arunachal Pradesh                        22,488   \n",
       "64   32                    Mizoram                        20,947   \n",
       "65   33  Andaman & Nicobar Islands                             -   \n",
       "\n",
       "   GSDP(19-20)-at current prices Share(18-19) GDP($ Billion)  \n",
       "0                              -       13.94%        399.921  \n",
       "1                      1,845,853        8.63%        247.629  \n",
       "2                      1,687,818        8.39%        240.726  \n",
       "3                              -        7.96%        228.290  \n",
       "4                      1,631,977        7.91%        226.806  \n",
       "..                           ...          ...            ...  \n",
       "61                        28,391        0.15%         17,060  \n",
       "62                             -        0.15%              -  \n",
       "63                             -        0.13%              -  \n",
       "64                        24,424        0.13%         17,797  \n",
       "65                             -            -              -  \n",
       "\n",
       "[66 rows x 6 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating DataFrame from the scraped data\n",
    "df = pd.DataFrame({'Rank':Rank,'State':State,'GSDP(18-19)-at current prices':GSDP1,'GSDP(19-20)-at current prices':GSDP2,'Share(18-19)':Share,'GDP($ Billion)':GDP_billion})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99fd875d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9ac55686",
   "metadata": {},
   "source": [
    "# 5. Scrape the details of top 100 songs on billiboard.com. Url = https:/www.billboard.com/ You have to find the\n",
    "following details:\n",
    "A) Song name\n",
    "B) Artist name\n",
    "C) Last week rank\n",
    "D) Peak rank\n",
    "E) Weeks on board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b12a4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first, connect to the webdriver\n",
    "driver=webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ef35751",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the webpage of mentioned url\n",
    "driver.get(\"https://www.billboard.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9084eb86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clicking on option button\n",
    "charts=driver.find_element(By.XPATH,'/html/body/div[3]/header/div/div[2]/div/div/div[2]/div[2]/div/div/nav/ul/li[1]/a').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47897404",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating empty lists\n",
    "Song_Name = []\n",
    "Artist_Name =[]\n",
    "Last_week_rank = []\n",
    "Peak_rank = []\n",
    "Weeks_on_board = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d49f316a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting urls for top 100 songs\n",
    "urls = driver.find_element(By.XPATH,'//a[@class=\"c-link  lrv-a-unstyle-link lrv-u-background-color-brand-secondary-dark lrv-u-color-grey-lightest lrv-u-color-grey-lightest:hover lrv-u-width-100p lrv-u-text-align-center lrv-a-hover-effect lrv-u-background-color-grey-dark:hover a-font-accent-fancy lrv-u-font-size-20 u-padding-tb-15 u-letter-spacing-0112 lrv-a-icon-after a-icon-magazine lrv-u-justify-content-center lrv-u-align-items-center lrv-a-unstyle-link u-width-100p@tablet u-width-235@mobile-max lrv-u-margin-t-050@mobile-max u-background-color-white@mobile-max u-color-black@mobile-max lrv-u-border-a-1@mobile-max lrv-u-border-color-brand-accent-red u-line-height-1\"]')\n",
    "page_url = urls.get_attribute(\"href\")\n",
    "driver.get(page_url)\n",
    "time.sleep(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "998e5b6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d0fc46a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "70295b1d",
   "metadata": {},
   "source": [
    "# 6. Scrape the details of Highest selling novels.\n",
    "A) Book name\n",
    "B) Author name\n",
    "C) Volumes sold\n",
    "D) Publisher\n",
    "E) Genre\n",
    " Url - https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b6fe5565",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first, connect to the webdriver\n",
    "driver=webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3e89c0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the webpage of mentioned url\n",
    "driver.get(\"https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "da20f0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating empty lists\n",
    "Book_name = []\n",
    "Author_name = []\n",
    "Volumes_sold = []\n",
    "Publisher = []\n",
    "Genre = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a524ea16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping book names data\n",
    "for i in driver.find_elements(By.XPATH,'//td[@class=\"left\"][2]'):\n",
    "    Book_name.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bcbd73ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "# scraping author names data\n",
    "for i in driver.find_elements(By.XPATH,'//td[@class=\"left\"][3]'):\n",
    "    Author_name.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ce070cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping data of volumes sold\n",
    "for i in driver.find_elements(By.XPATH,'//td[@class=\"left\"][4]'):\n",
    "    Volumes_sold.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b59ee7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping data of publisher names\n",
    "for i in driver.find_elements(By.XPATH,'//td[@class=\"left\"][5]'):\n",
    "    Publisher.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e4fd490a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping  data of genre\n",
    "for i in driver.find_elements(By.XPATH,'//td[@class=\"last left\"]'):\n",
    "    Genre.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "92eb0f2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book Name</th>\n",
       "      <th>Author</th>\n",
       "      <th>Volume sold</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Da Vinci Code,The</td>\n",
       "      <td>Brown, Dan</td>\n",
       "      <td>5,094,805</td>\n",
       "      <td>Transworld</td>\n",
       "      <td>Crime, Thriller &amp; Adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Harry Potter and the Deathly Hallows</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,475,152</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Harry Potter and the Philosopher's Stone</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,200,654</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Harry Potter and the Order of the Phoenix</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,179,479</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fifty Shades of Grey</td>\n",
       "      <td>James, E. L.</td>\n",
       "      <td>3,758,936</td>\n",
       "      <td>Random House</td>\n",
       "      <td>Romance &amp; Sagas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Ghost,The</td>\n",
       "      <td>Harris, Robert</td>\n",
       "      <td>807,311</td>\n",
       "      <td>Random House</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Happy Days with the Naked Chef</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>794,201</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Hunger Games,The:Hunger Games Trilogy</td>\n",
       "      <td>Collins, Suzanne</td>\n",
       "      <td>792,187</td>\n",
       "      <td>Scholastic Ltd.</td>\n",
       "      <td>Young Adult Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Lost Boy,The:A Foster Child's Search for the L...</td>\n",
       "      <td>Pelzer, Dave</td>\n",
       "      <td>791,507</td>\n",
       "      <td>Orion</td>\n",
       "      <td>Biography: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Jamie's Ministry of Food:Anyone Can Learn to C...</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>791,095</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Book Name            Author  \\\n",
       "0                                   Da Vinci Code,The        Brown, Dan   \n",
       "1                Harry Potter and the Deathly Hallows     Rowling, J.K.   \n",
       "2            Harry Potter and the Philosopher's Stone     Rowling, J.K.   \n",
       "3           Harry Potter and the Order of the Phoenix     Rowling, J.K.   \n",
       "4                                Fifty Shades of Grey      James, E. L.   \n",
       "..                                                ...               ...   \n",
       "95                                          Ghost,The    Harris, Robert   \n",
       "96                     Happy Days with the Naked Chef     Oliver, Jamie   \n",
       "97              Hunger Games,The:Hunger Games Trilogy  Collins, Suzanne   \n",
       "98  Lost Boy,The:A Foster Child's Search for the L...      Pelzer, Dave   \n",
       "99  Jamie's Ministry of Food:Anyone Can Learn to C...     Oliver, Jamie   \n",
       "\n",
       "   Volume sold        Publisher                        Genre  \n",
       "0    5,094,805       Transworld  Crime, Thriller & Adventure  \n",
       "1    4,475,152       Bloomsbury           Children's Fiction  \n",
       "2    4,200,654       Bloomsbury           Children's Fiction  \n",
       "3    4,179,479       Bloomsbury           Children's Fiction  \n",
       "4    3,758,936     Random House              Romance & Sagas  \n",
       "..         ...              ...                          ...  \n",
       "95     807,311     Random House   General & Literary Fiction  \n",
       "96     794,201          Penguin        Food & Drink: General  \n",
       "97     792,187  Scholastic Ltd.          Young Adult Fiction  \n",
       "98     791,507            Orion           Biography: General  \n",
       "99     791,095          Penguin        Food & Drink: General  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating dataframe for scraped data\n",
    "Novels = pd.DataFrame({})\n",
    "Novels['Book Name'] = Book_name\n",
    "Novels['Author'] = Author_name\n",
    "Novels['Volume sold'] = Volumes_sold\n",
    "Novels['Publisher'] = Publisher\n",
    "Novels['Genre'] = Genre\n",
    "Novels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "030fd5b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b4ea402e",
   "metadata": {},
   "source": [
    "# 7. Scrape the details most watched tv series of all time from imdb.com.\n",
    "Url = https://www.imdb.com/list/ls095964455/ You have\n",
    "to find the following details:\n",
    "A) Name\n",
    "B) Year span\n",
    "C) Genre\n",
    "D) Run time\n",
    "E) Ratings\n",
    "F) Votes \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "37ca0488",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first, connect to the webdriver\n",
    "driver=webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5c894e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the webpage of mentioned url\n",
    "driver.get(\"https://www.imdb.com/list/ls095964455/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bfc0b8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating empty lists\n",
    "Name = []\n",
    "Year_span = []\n",
    "Genre = []\n",
    "Run_time = []\n",
    "Ratings = []\n",
    "Votes = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bf838f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraped data of Names\n",
    "for i in driver.find_elements(By.XPATH,\"//h3[@class='lister-item-header']/a\"):\n",
    "    Name.append(i.text)\n",
    "    \n",
    "    \n",
    "# scraped data of Year span\n",
    "for i in driver.find_elements(By.XPATH,\"//span[@class='lister-item-year text-muted unbold']\"):\n",
    "    Year_span.append(i.text)\n",
    "    \n",
    "    \n",
    "# scraped data of Genre\n",
    "for i in driver.find_elements(By.XPATH,\"//span[@class='genre']\"):\n",
    "    Genre.append(i.text)\n",
    "    \n",
    "    \n",
    "# scraped data of Run time\n",
    "for i in driver.find_elements(By.XPATH,\"//span[@class='runtime']\"):\n",
    "    Run_time.append(i.text)\n",
    "    \n",
    "    \n",
    "# scraped data of Ratings\n",
    "for i in driver.find_elements(By.XPATH,\"//div[@class='ipl-rating-star small']//span[2]\"):\n",
    "    Ratings.append(i.text)\n",
    "    \n",
    "    \n",
    "# scraped data of Votes\n",
    "for i in driver.find_elements(By.XPATH,\"//div[@class='lister-item-content']//p[4]/span[2]\"):\n",
    "    Votes.append(i.text) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "30dd7179",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Year Span</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Run Time</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Game of Thrones</td>\n",
       "      <td>(2011–2019)</td>\n",
       "      <td>Action, Adventure, Drama</td>\n",
       "      <td>4,189 min</td>\n",
       "      <td>9.2</td>\n",
       "      <td>2,226,703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stranger Things</td>\n",
       "      <td>(2016–2025)</td>\n",
       "      <td>Drama, Fantasy, Horror</td>\n",
       "      <td>51 min</td>\n",
       "      <td>8.7</td>\n",
       "      <td>1,293,628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Walking Dead</td>\n",
       "      <td>(2010–2022)</td>\n",
       "      <td>Drama, Horror, Thriller</td>\n",
       "      <td>44 min</td>\n",
       "      <td>8.1</td>\n",
       "      <td>1,056,282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13 Reasons Why</td>\n",
       "      <td>(2017–2020)</td>\n",
       "      <td>Drama, Mystery, Thriller</td>\n",
       "      <td>60 min</td>\n",
       "      <td>7.5</td>\n",
       "      <td>310,133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The 100</td>\n",
       "      <td>(2014–2020)</td>\n",
       "      <td>Drama, Mystery, Sci-Fi</td>\n",
       "      <td>43 min</td>\n",
       "      <td>7.6</td>\n",
       "      <td>269,257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Reign</td>\n",
       "      <td>(2013–2017)</td>\n",
       "      <td>Drama</td>\n",
       "      <td>42 min</td>\n",
       "      <td>7.5</td>\n",
       "      <td>53,278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>A Series of Unfortunate Events</td>\n",
       "      <td>(2017–2019)</td>\n",
       "      <td>Adventure, Comedy, Drama</td>\n",
       "      <td>50 min</td>\n",
       "      <td>7.8</td>\n",
       "      <td>65,358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Criminal Minds</td>\n",
       "      <td>(2005– )</td>\n",
       "      <td>Crime, Drama, Mystery</td>\n",
       "      <td>42 min</td>\n",
       "      <td>8.1</td>\n",
       "      <td>213,175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Scream: The TV Series</td>\n",
       "      <td>(2015–2019)</td>\n",
       "      <td>Comedy, Crime, Drama</td>\n",
       "      <td>45 min</td>\n",
       "      <td>7</td>\n",
       "      <td>44,372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>The Haunting of Hill House</td>\n",
       "      <td>(2018)</td>\n",
       "      <td>Drama, Horror, Mystery</td>\n",
       "      <td>572 min</td>\n",
       "      <td>8.6</td>\n",
       "      <td>278,073</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Name    Year Span                     Genre  \\\n",
       "0                  Game of Thrones  (2011–2019)  Action, Adventure, Drama   \n",
       "1                  Stranger Things  (2016–2025)    Drama, Fantasy, Horror   \n",
       "2                 The Walking Dead  (2010–2022)   Drama, Horror, Thriller   \n",
       "3                   13 Reasons Why  (2017–2020)  Drama, Mystery, Thriller   \n",
       "4                          The 100  (2014–2020)    Drama, Mystery, Sci-Fi   \n",
       "..                             ...          ...                       ...   \n",
       "95                           Reign  (2013–2017)                     Drama   \n",
       "96  A Series of Unfortunate Events  (2017–2019)  Adventure, Comedy, Drama   \n",
       "97                  Criminal Minds     (2005– )     Crime, Drama, Mystery   \n",
       "98           Scream: The TV Series  (2015–2019)      Comedy, Crime, Drama   \n",
       "99      The Haunting of Hill House       (2018)    Drama, Horror, Mystery   \n",
       "\n",
       "     Run Time Ratings      Votes  \n",
       "0   4,189 min     9.2  2,226,703  \n",
       "1      51 min     8.7  1,293,628  \n",
       "2      44 min     8.1  1,056,282  \n",
       "3      60 min     7.5    310,133  \n",
       "4      43 min     7.6    269,257  \n",
       "..        ...     ...        ...  \n",
       "95     42 min     7.5     53,278  \n",
       "96     50 min     7.8     65,358  \n",
       "97     42 min     8.1    213,175  \n",
       "98     45 min       7     44,372  \n",
       "99    572 min     8.6    278,073  \n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating dataframe for scraped data\n",
    "TV_Series = pd.DataFrame({})\n",
    "TV_Series['Name'] = Name\n",
    "TV_Series['Year Span'] = Year_span\n",
    "TV_Series['Genre'] = Genre\n",
    "TV_Series['Run Time'] = Run_time\n",
    "TV_Series['Ratings'] = Ratings\n",
    "TV_Series['Votes'] = Votes\n",
    "TV_Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c80859",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7e6f0695",
   "metadata": {},
   "source": [
    "# 8. Details of Datasets from UCI machine learning repositories.\n",
    "Url = https://archive.ics.uci.edu/ You\n",
    "have to find the following details:\n",
    "A) Dataset name\n",
    "B) Data type\n",
    "C) Task\n",
    "D) Attribute type\n",
    "E) No of instances\n",
    "F) No of attribute G) Year\n",
    " Note: - from the home page you have to go to the Show All Dataset page through code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "146a7950",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first, connect to the webdriver\n",
    "driver=webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c7bf0b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the webpage of mentioned url\n",
    "driver.get(\"https://archive.ics.uci.edu/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dd66d512",
   "metadata": {},
   "outputs": [],
   "source": [
    "#THIS LINK IS NOT OPEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81fed1da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
